{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "\n",
    "# <nbformat>3.0</nbformat>\n",
    "\n",
    "# <markdowncell>\n",
    "# <codecell>\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from collections import Counter\n",
    "from scipy import spatial\n",
    "import sys\n",
    "import networkx as nx\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "\n",
    "def str_to_bool(s):\n",
    "    if s == 'True':\n",
    "         return True\n",
    "    elif s == 'False':\n",
    "         return False\n",
    "    else:\n",
    "         raise ValueError # evil ValueError that doesn't tell you what the wrong value was\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###\n",
    "###   Compute random genes matching for distance and chromosome\n",
    "###\n",
    "###############################################################################\n",
    "\n",
    "def negative_eQTL_oneSNP(eQTL, distance_threshold, egene_list):\n",
    "    '''\n",
    "    match the eQTL using chr and distance\n",
    "    '''\n",
    "    eSNP_pos = eQTL['SNP_POS']\n",
    "    echr = eQTL['SNP_CHR']\n",
    "    eDistance = eQTL['DISTANCE']\n",
    "    egene = eQTL['GENE']\n",
    "    \n",
    "    genes_chr = GRCh37_genes[GRCh37_genes['Chromosome/scaffold name'] == str(echr)]\n",
    "    t = genes_chr.apply(lambda x: abs(x['Gene Start (bp)'] - eSNP_pos) < distance_threshold, axis=1)\n",
    "    \n",
    "    if sum(t)>1:\n",
    "        neg_gene = genes_chr[t].sample(1)\n",
    "        while neg_gene.index[0] in egene_list:\n",
    "            neg_gene = genes_chr[t].sample(1)\n",
    "    else: \n",
    "        print \"No negative gene found\"       \n",
    "    return neg_gene.index[0]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def negative_eQTL_onecell(eQTL, distance_threshold = 1000000):\n",
    "\n",
    "    print 'Compute negative SNP-gene pairs match for distance and chromosome'\n",
    "    \n",
    "    eQTL_nega = pd.DataFrame()\n",
    "    \n",
    "    for name, df in eQTL.groupby('SNP_CHR'):\n",
    "        print name\n",
    "        eQTL_pergene = df.loc[df.groupby('GENE')['P-VALUE'].idxmin()]    ## One Lead SNP per gene\n",
    "        eQTL_pergene = eQTL_pergene.reset_index(drop=True)\n",
    "        negative_genes = eQTL_pergene.apply(lambda x: negative_eQTL_oneSNP(x,distance_threshold, list(eQTL_pergene['GENE'])),axis=1)\n",
    "        negative_genes = GRCh37_genes.loc[np.array(negative_genes)].reset_index(drop=True)\n",
    "\n",
    "        eQTL_nega_pergene = eQTL_pergene.merge(negative_genes, left_index=True, right_index=True)\n",
    "        eQTL_nega_pergene = eQTL_nega_pergene[['SNP', 'SNP_CHR', 'SNP_POS', 'Associated Gene Name', 'Gene Start (bp)','P-VALUE']]\n",
    "        eQTL_nega_pergene.columns = [['SNP', 'SNP_CHR', 'SNP_POS', 'GENE', 'GENE_START_POS','P-VALUE']]\n",
    "        eQTL_nega_pergene['DISTANCE'] = abs(eQTL_nega_pergene['SNP_POS'] - eQTL_nega_pergene['GENE_START_POS'])\n",
    "        \n",
    "        eQTL_nega = eQTL_nega.append(eQTL_nega_pergene)\n",
    "        \n",
    "    return eQTL_nega\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###\n",
    "###   Retrive information from PC-HiC data\n",
    "###\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "######  SNP-gene pairs that locate near fragments\n",
    "\n",
    "def eQTL_in_fragments_one_chr(eQTL_df, contacting_df, SNP_window, promoter_window, \n",
    "                              fragments = ['baitStart', 'baitEnd', 'oeStart', 'oeEnd']):\n",
    "    '''\n",
    "    e-SNP near bait/oe, and promoter of the e-gene near oe/bait\n",
    "    '''\n",
    "    \n",
    "    N = len(contacting_df)\n",
    "    Start1, End1, Start2, End2 = fragments\n",
    "\n",
    "    # e-SNP\n",
    "    SNP_positions = np.reshape(eQTL_df['SNP_POS'],[len(eQTL_df),1])\n",
    "    SNP_tree = spatial.KDTree(SNP_positions)\n",
    "\n",
    "    frag1_start = np.reshape(contacting_df[Start1],[N,1])\n",
    "    SNP_near_frag1Start = SNP_tree.query_ball_point(frag1_start, SNP_window)\n",
    "    frag1_end = np.reshape(contacting_df[End1],[N,1])\n",
    "    SNP_near_frag1End = SNP_tree.query_ball_point(frag1_end, SNP_window)\n",
    "    SNP_near_frag1 = [SNP_near_frag1Start[i] + SNP_near_frag1End[i] for i in xrange(N)]\n",
    "\n",
    "    # e-gene\n",
    "    gene_start = np.reshape(eQTL_df['GENE_START_POS'], [len(eQTL_df),1])\n",
    "    gene_tree = spatial.KDTree(gene_start)\n",
    "\n",
    "    frag2_start = np.reshape(contacting_df[Start2], [N,1])\n",
    "    gene_near_frag2Start = gene_tree.query_ball_point(frag2_start, promoter_window)\n",
    "    frag2_end = np.reshape(contacting_df[End2], [N,1])\n",
    "    gene_near_frag2End = gene_tree.query_ball_point(frag2_end, promoter_window)\n",
    "    gene_near_frag2 = [gene_near_frag2Start[i] + gene_near_frag2End[i] for i in xrange(N)]\n",
    "    \n",
    "    SNPID = np.array(SNP_near_frag1)[np.array([len(np.intersect1d(SNP_near_frag1[t],gene_near_frag2[t]))>0 \n",
    "                                               for t in xrange(len(SNP_near_frag1))])]\n",
    "    geneID = np.array(gene_near_frag2)[np.array([len(np.intersect1d(SNP_near_frag1[t],gene_near_frag2[t]))>0 \n",
    "                                                 for t in xrange(len(SNP_near_frag1))])]\n",
    "    QTLID = [list(np.intersect1d(SNPID[t], geneID[t])) for t in xrange(len(SNPID))]\n",
    "    \n",
    "    return list(set([x for sublist in QTLID for x in sublist]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######   Retrive SNPs that locate in PIR\n",
    "\n",
    "\n",
    "def SNP_in_PIR(eQTL, contacting_df, PIR_window = 1000):\n",
    "    gene_promoter = eQTL['GENE']\n",
    "    SNP = eQTL['SNP']\n",
    "    SNP_POS = eQTL['SNP_POS']\n",
    "\n",
    "    gene_promoter_idx = np.where([gene_promoter in str(x).split(';') for x in list(contacting_df['baitName'])])[0]\n",
    "    gene_promoter_window = contacting_df.iloc[gene_promoter_idx]\n",
    "\n",
    "    # if len(gene_promoter_window)==0:\n",
    "    #     print gene_promoter\n",
    "\n",
    "    left = np.array(gene_promoter_window['oeStart']) - PIR_window\n",
    "    right = np.array(gene_promoter_window['oeEnd']) + PIR_window\n",
    "\n",
    "    if sum([(t[0] < SNP_POS and t[1] > SNP_POS) for t in zip(left,right)]) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "\n",
    "######  Compute degree of contacts (0/1/2) from genes to the SNPs\n",
    "\n",
    "\n",
    "def map_to_1based(anarray):\n",
    "    return dict(zip(set(anarray), xrange(len(anarray))))\n",
    "\n",
    "\n",
    "def bait_names(mapped_1based_idx, names):\n",
    "    return dict(zip(mapped_1based_idx, names))\n",
    "\n",
    "def edges_inbetween(D, n_nodes):\n",
    "    ### input: a graph object\n",
    "    ### return the degree of contacts between nodes: 1/2/0\n",
    "    goal_matrix = np.ones([n_nodes,n_nodes]) * 100\n",
    "    for n,nbrs in D.adjacency_iter():\n",
    "        # assign 1 to the direct linkage\n",
    "        goal_matrix[n][D[n].keys()] = 1\n",
    "        # assign 2 to the indirect linkage\n",
    "        for t in D[n].keys():\n",
    "            goal_matrix[n][D[t].keys()] = map(lambda x: min(x), \n",
    "                                              zip(list(goal_matrix[n][D[t].keys()]),\n",
    "                                                  [goal_matrix[n][t]+1] * len(goal_matrix[n][D[t].keys()])))\n",
    "    goal_matrix[goal_matrix==100] = 0\n",
    "    np.fill_diagonal(goal_matrix,0)\n",
    "    return goal_matrix\n",
    "\n",
    "\n",
    "\n",
    "def contacting_to_degree(data,edge_threshold=0):\n",
    "    ## obtain the nodes and the weights edges\n",
    "    if edge_threshold != 0:\n",
    "        data = data.iloc[np.where(data['obs_exp']>edge_threshold)[0]]\n",
    "    fragment_len = max(max(data['i']),max(data['j'])) + 1\n",
    "    nodes = range(fragment_len)\n",
    "    weighted_edges = zip(list(data['i']),list(data['j']),list(data['obs_exp']))\n",
    "    print fragment_len\n",
    "    \n",
    "    ## construct the graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_weighted_edges_from(weighted_edges)\n",
    "    \n",
    "    ## obtain number of edges between the bins\n",
    "    number_of_edges_inbetween = edges_inbetween(G, fragment_len)\n",
    "    return G, number_of_edges_inbetween\n",
    "\n",
    "\n",
    "\n",
    "def compute_frag_by_frag(d, celltype):\n",
    "    anarray = list(d['baitID']) + list(d['oeID'])\n",
    "    t = map_to_1based(anarray)\n",
    "    d['baitID'] = map(lambda x: t[x], list(d['baitID']))\n",
    "    d['oeID'] = map(lambda x: t[x], list(d['oeID']))\n",
    "    baitsnames = bait_names(list(d['baitID']) + list(d['oeID']), list(d['baitName']) + list(d['oeName']))\n",
    "\n",
    "    df = d[['baitID','oeID',celltype]]\n",
    "    df.columns = ['i','j','obs_exp']\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    G,frag_by_frag = contacting_to_degree(df,edge_threshold=0)\n",
    "    frag_by_frag = pd.DataFrame(frag_by_frag)\n",
    "    frag_by_frag.index = baitsnames.values()\n",
    "    frag_by_frag.loc['NOGENE'] = [0]*len(frag_by_frag)\n",
    "    \n",
    "    frag_by_frag = frag_by_frag.drop([\".\"])\n",
    "    frag_by_frag = frag_by_frag.to_dict(orient = 'index')\n",
    "    \n",
    "    return frag_by_frag\n",
    "\n",
    "\n",
    "def find_the_key(frag_by_frag, gg):\n",
    "    '''\n",
    "    To deal with the baits' names, which has several gene names in one string\n",
    "    '''\n",
    "    gg_in_frag = np.where(map(lambda x: gg in str(x), frag_by_frag.keys()))[0]\n",
    "    if len(gg_in_frag) > 0:\n",
    "        temp = np.array(frag_by_frag.keys())[np.array(gg_in_frag)]\n",
    "        return np.random.choice(temp)\n",
    "    else:\n",
    "        return 'NOGENE' \n",
    "\n",
    "\n",
    "def degree_of_contact_SNP_gene(eQTL_df, contacting_df, frag_by_frag, PIR_window=2000):\n",
    "\n",
    "    ### find the other fragments where eSNP locate in \n",
    "    left = np.array(contacting_df['oeStart']) - PIR_window\n",
    "    right = np.array(contacting_df['oeEnd']) + PIR_window\n",
    "    SNPs_PIR = eQTL_df.apply(lambda x: [x['SNP_POS'] in range(t[0],t[1]) for t in zip(left,right)], axis=1)\n",
    "    SNPs_PIR = SNPs_PIR.apply(lambda x: list(np.where(x)[0]))   ## a list of lists\n",
    "    eQTL_df['SNP_contacting_df_idx'] = list(SNPs_PIR)\n",
    "    \n",
    "    ### find the degree of contact by using frag_by_frag dictionary\n",
    "    degree_contact = eQTL_df.apply(lambda eq: [frag_by_frag[find_the_key(frag_by_frag, eq['GENE'])][contacting_df.iloc[t]['oeID']] \n",
    "                                               for t in eq['SNP_contacting_df_idx']], axis=1)\n",
    "    \n",
    "    return degree_contact\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######   Annotate the SNP-gene pairs\n",
    "\n",
    "\n",
    "def eQTL_in_fragments_one_cell(eQTL, pairs):\n",
    "\n",
    "    print 'Compute whether the eQTL pair fall in any promoter-PIR pair'\n",
    "    \n",
    "    contacting_cell = pairs[list(pairs.columns[:11])+[celltype]]  \n",
    "    contacting_cell = contacting_cell[contacting_cell[celltype] > 0]   \n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "    for name, df in eQTL.groupby('SNP_CHR'):\n",
    "        contacting_pairs = contacting_cell[contacting_cell['baitChr'] == str(name)]\n",
    "        eQTL_pergene = df.loc[df.groupby('GENE')['P-VALUE'].idxmin()]    ## One Lead SNP per gene\n",
    "        \n",
    "        ## approach 1: use KDTree: not right\n",
    "        # functional_contacting_idx1 = eQTL_in_fragments_one_chr(eQTL_pergene, contacting_pairs, SNP_window_for_PHiC, promoter_window_for_PHiC)\n",
    "        # functional_contacting_idx2 = eQTL_in_fragments_one_chr(eQTL_pergene, contacting_pairs, SNP_window_for_PHiC, promoter_window_for_PHiC,\n",
    "        #                                                        fragments = ['oeStart', 'oeEnd','baitStart', 'baitEnd'])\n",
    "        # contact_vector = np.array([0] * len(eQTL_pergene))\n",
    "        # contact_vector[np.array(list(set(functional_contacting_idx1+functional_contacting_idx2)))] = 1\n",
    "\n",
    "        ## approach 2: can only compute the direct contacts\n",
    "        # functional_contacting_idx = eQTL_pergene.apply(lambda x: SNP_in_PIR(x, contacting_pairs),axis=1)\n",
    "        # contact_vector = np.array(functional_contacting_idx)\n",
    "        # eQTL_pergene['contacting'] = contact_vector\n",
    "\n",
    "        ## approach 3: compute the degree of contacts\n",
    "        frag2 = compute_frag_by_frag(contacting_pairs,celltype) \n",
    "        degree_contact = degree_of_contact_SNP_gene(eQTL_pergene, contacting_pairs, frag2)\n",
    "\n",
    "        contact_vector = np.zeros(len(eQTL_pergene))\n",
    "        contact_vector[np.where(map(lambda x: 2 in x, degree_contact))[0]] = 2\n",
    "        contact_vector[np.where(map(lambda x: 1 in x, degree_contact))[0]] = 1\n",
    "\n",
    "        eQTL_pergene['contacting'] = contact_vector\n",
    "        \n",
    "        result_df = result_df.append(eQTL_pergene)\n",
    "\n",
    "        print name\n",
    "        print Counter(contact_vector)\n",
    "                \n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######   Save the bed files for intersection with TFB motif\n",
    "\n",
    "def save_bed_files(result_df, SNP_window, promoter_window, negative_set = False):\n",
    "\n",
    "    if negative_set:\n",
    "        result_df.to_csv(os.path.join(DATA_DIR, 'eQTL/FairFax/%s_cis_%i_fdr05_50kb_negative_annotated.csv' % (celltype,chr)), sep='\\t',index=False)\n",
    "    else:\n",
    "        result_df.to_csv(os.path.join(DATA_DIR, 'eQTL/FairFax/%s_cis_%i_fdr05_50kb_annotated.csv' % (celltype,chr)), sep='\\t',index=False)        \n",
    "\n",
    "    SNP_bed = []\n",
    "    SNP_bed.append(['chr%i'% x for x in (result_df['SNP_CHR'])])\n",
    "    SNP_bed.append(list(np.array(result_df['SNP_POS']) - SNP_window))\n",
    "    SNP_bed.append(list(np.array(result_df['SNP_POS']) + SNP_window))\n",
    "    SNP_bed.append(list(result_df['SNP']))\n",
    "    SNP_bed = pd.DataFrame(SNP_bed).transpose()\n",
    "    if negative_set:\n",
    "        SNP_bed.to_csv(os.path.join(DATA_DIR, 'intermediate/%s/PCHiC_peak_matrix_cutoff5_%i_eSNP_negativeset.bed'% (celltype, chr)),\n",
    "                   sep='\\t',index=False, header=False)\n",
    "    else:\n",
    "        SNP_bed.to_csv(os.path.join(DATA_DIR, 'intermediate/%s/PCHiC_peak_matrix_cutoff5_%i_eSNP.bed' % (celltype, chr)),\n",
    "                   sep='\\t',index=False, header=False)\n",
    "    \n",
    "    ## \n",
    "    promoter_bed = []\n",
    "    promoter_bed.append(['chr%i'% x for x in (result_df['SNP_CHR'])])\n",
    "    promoter_bed.append(list(np.array(result_df['GENE_START_POS']) - promoter_window))\n",
    "    promoter_bed.append(list(np.array(result_df['GENE_START_POS']) + promoter_window))\n",
    "    promoter_bed.append(list(result_df['GENE']))\n",
    "    promoter_bed = pd.DataFrame(promoter_bed).transpose()\n",
    "    if negative_set:\n",
    "        promoter_bed.to_csv(os.path.join(DATA_DIR, 'intermediate/%s/PCHiC_peak_matrix_cutoff5_%i_egene_negativeset.bed'% (celltype, chr)),\n",
    "                   sep='\\t',index=False, header=False)\n",
    "    else:\n",
    "        promoter_bed.to_csv(os.path.join(DATA_DIR, 'intermediate/%s/PCHiC_peak_matrix_cutoff5_%i_egene.bed'% (celltype, chr)),\n",
    "                   sep='\\t',index=False, header=False)\n",
    "        \n",
    "        \n",
    "\n",
    "def readin_intermediate_result(celltype, SNP_window, promoter_window, negative_set=False):\n",
    "    '''\n",
    "    At first used to recover eQTL pairs from bed files. \n",
    "    Not used since the annotated eQTLs are saved.\n",
    "    '''\n",
    "    if negative_set:\n",
    "        fn_SNP = 'PCHiC_peak_matrix_cutoff5_%s_eSNP_negative.bed' % chr\n",
    "        fn_gene = 'PCHiC_peak_matrix_cutoff5_%s_egene_negative.bed' % chr\n",
    "    else:\n",
    "        fn_SNP = 'PCHiC_peak_matrix_cutoff5_%s_eSNP.bed' % chr\n",
    "        fn_gene = 'PCHiC_peak_matrix_cutoff5_%s_egene.bed' % chr\n",
    "    a = pd.read_csv(os.path.join(DATA_DIR, 'intermediate/%s/%s' % (celltype,fn_SNP)),sep='\\t',header=None)\n",
    "    b = pd.read_csv(os.path.join(DATA_DIR, 'intermediate/%s/%s' % (celltype,fn_gene)),sep='\\t',header=None)\n",
    "    \n",
    "    inter_result = pd.concat((a,b),axis=1)\n",
    "    inter_result.columns = ['SNP_CHR','SNP_POS','non','SNP','GENE_chr','GENE_START_POS','NAN','GENE']\n",
    "    inter_result = inter_result[['SNP_CHR','SNP_POS','SNP','GENE_chr','GENE_START_POS','GENE']]\n",
    "    inter_result['SNP_POS'] = inter_result['SNP_POS'] + SNP_window\n",
    "    inter_result['GENE_START_POS'] = inter_result['GENE_START_POS'] + promoter_window\n",
    "    return inter_result\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###\n",
    "###   Scan the bed files for known motifs using fimo (in bash)\n",
    "###\n",
    "###############################################################################\n",
    "\n",
    "#### run the following codes in DATA_DIR\n",
    "#### bash TFBS.sh ${celltype} eSNP\n",
    "#### bash TFBS.sh ${celltype} gene\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###\n",
    "###   Annotate the pairs with TF motif information\n",
    "###\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def merge_TF_motif(result_df, negative_set=False):\n",
    "    if negative_set:\n",
    "        f1 = 'fimo.output.%s.eSNP.%i.negativeset.bed' % (celltype,int(chr))\n",
    "        f2 = 'fimo.output.%s.egene.%i.negativeset.bed' % (celltype,int(chr))\n",
    "    else:\n",
    "        f1 = 'fimo.output.%s.eSNP.%i.bed' % (celltype,int(chr))\n",
    "        f2 = 'fimo.output.%s.egene.%i.bed' % (celltype,int(chr))\n",
    "        \n",
    "    # read in eQTLs with TF motif annotated\n",
    "    eSNP_tf = pd.read_csv(os.path.join(DATA_DIR,'intermediate/%s/motif' % celltype,f1),sep='\\t',header=None)\n",
    "    egene_tf = pd.read_csv(os.path.join(DATA_DIR,'intermediate/%s/motif' % celltype,f2),sep='\\t',header=None)\n",
    "    \n",
    "    eSNP_tf.columns = ['SNPID','chr','start','end','motif_SNP']\n",
    "    egene_tf.columns = ['geneID','chr','start','end','motif_gene']\n",
    "    \n",
    "    eSNP_tf = pd.DataFrame(eSNP_tf.groupby('SNPID')['motif_SNP'].apply(lambda x:list(set(x))))\n",
    "    egene_tf = pd.DataFrame(egene_tf.groupby('geneID')['motif_gene'].apply(lambda x:list(set(x))))\n",
    "    \n",
    "    result_df = result_df.merge(eSNP_tf, left_on='SNP',right_index=True, how='left')\n",
    "    result_df = result_df.merge(egene_tf, left_on='GENE',right_index=True, how='left')\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_all_TF_motif(result_df, negative_set=False):\n",
    "    if negative_set:\n",
    "        f1 = '%s.eSNP.%i.negativeset.bed' % (celltype,int(chr))\n",
    "        f2 = '%s.egene.%i.negativeset.bed' % (celltype,int(chr))\n",
    "    else:\n",
    "        f1 = '%s.eSNP.%i.bed' % (celltype,int(chr))\n",
    "        f2 = '%s.egene.%i.bed' % (celltype,int(chr))\n",
    "        \n",
    "    # read in eQTLs with TF motif annotated\n",
    "    eSNP_tf = pd.read_csv(os.path.join(DATA_DIR,'intermediate/%s/motif' % celltype,f1),sep='\\t',header=None)\n",
    "    egene_tf = pd.read_csv(os.path.join(DATA_DIR,'intermediate/%s/motif' % celltype,f2),sep='\\t',header=None)\n",
    "    \n",
    "    eSNP_tf.columns = ['SNPID','chr','start','end','motif_SNP_all']\n",
    "    egene_tf.columns = ['geneID','chr','start','end','motif_gene_all']\n",
    "    \n",
    "    eSNP_tf = pd.DataFrame(eSNP_tf.groupby('SNPID')['motif_SNP_all'].apply(lambda x:list(set(x))))\n",
    "    egene_tf = pd.DataFrame(egene_tf.groupby('geneID')['motif_gene_all'].apply(lambda x:list(set(x))))\n",
    "    \n",
    "    result_df = result_df.merge(eSNP_tf, left_on='SNP',right_index=True, how='left')\n",
    "    result_df = result_df.merge(egene_tf, left_on='GENE',right_index=True, how='left')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###\n",
    "###   Retrive information from ATAC-seq data\n",
    "###\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "\n",
    "def readin_ATACseq(filename):\n",
    "    ATACseq = pd.read_csv(filename,sep='\\t', header=None)\n",
    "    ATACseq = ATACseq[[0,1,2,9]]\n",
    "    ATACseq.columns = ['chr','Start','End','count']\n",
    "    ATACseq = ATACseq[ATACseq['chr'] == 'chr%i'%chr].reset_index(drop=True)\n",
    "    return ATACseq\n",
    "\n",
    "def eQTL_in_ATACseq_one_chr(eQTL_pos, ATAC_regions, ATAC_window = 1000):\n",
    "\n",
    "    N = len(ATAC_regions)\n",
    "    eQTL_tree = spatial.KDTree(eQTL_pos)\n",
    "\n",
    "    frag_start = np.reshape(ATAC_regions['Start'],[N,1])\n",
    "    eQTL_near_fragStart = eQTL_tree.query_ball_point(frag_start, ATAC_window)\n",
    "    frag_end = np.reshape(ATAC_regions['End'],[N,1])\n",
    "    eQTL_near_fragEnd = eQTL_tree.query_ball_point(frag_end, ATAC_window)\n",
    "\n",
    "    eQTL_near_frag = [list(set(eQTL_near_fragStart[i] + eQTL_near_fragEnd[i])) for i in xrange(N)]\n",
    "    eQTLID = [x for x in eQTL_near_frag if len(x) > 0]\n",
    "    eQTLID = list(set([a for b in eQTLID for a in b]))\n",
    "    \n",
    "    x = np.zeros(len(eQTL_pos))\n",
    "    x[eQTLID] = 1\n",
    "    return x\n",
    "\n",
    "\n",
    "# In[119]:\n",
    "\n",
    "def eQTL_in_ATACseq_one_cell(eQTL, ATAC, SNP_ATAC_window = 1000, gene_ATAC_window = 2000):\n",
    "    \n",
    "    if \"ATAC_SNP\" in eQTL.columns:\n",
    "        del eQTL['ATAC_SNP']\n",
    "        del eQTL['ATAC_gene']\n",
    "    if 1:\n",
    "        result_df = pd.DataFrame()\n",
    "        for name, g in eQTL.groupby('SNP_CHR'):\n",
    "            ## eSNP\n",
    "            eSNP_pos = np.reshape(g['SNP_POS'],[len(g),1])\n",
    "            ATAC_SNP_vector = eQTL_in_ATACseq_one_chr(eSNP_pos,ATAC, SNP_ATAC_window)\n",
    "            ## egene\n",
    "            egene_pos = np.reshape(g['GENE_START_POS'],[len(g),1])\n",
    "            ATAC_gene_vector = eQTL_in_ATACseq_one_chr(egene_pos,ATAC, gene_ATAC_window)\n",
    "        \n",
    "            ## ATAC profile\n",
    "            ATAC_eQTL = pd.DataFrame({'ATAC_SNP':ATAC_SNP_vector,'ATAC_gene':ATAC_gene_vector})\n",
    "            g = pd.concat((g.reset_index(drop=True),ATAC_eQTL),axis=1)\n",
    "            result_df = result_df.append(g)        \n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "###\n",
    "###   Main scripts\n",
    "###\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "\n",
    "######   Global parameters\n",
    "\n",
    "DATA_DIR = '/Users/Yuan/Documents/BLab/Predict_target_genes/data'\n",
    "# DATA_DIR = '/scratch1/battle-fs1/heyuan/Predict_target_gene'\n",
    "\n",
    "# chr = int(os.environ['chr'])    ### do it chromosome by chromosome, because of the huge contact matrix\n",
    "celltype = \"Mon\"\n",
    "\n",
    "SNP_ATAC_window = 2000\n",
    "gene_ATAC_window = 5000\n",
    "\n",
    "for i in xrange(2):\n",
    "    chr=i+1\n",
    "\n",
    "    try:\n",
    "        DNase_fn = os.path.join(DATA_DIR, 'ATACseq/ENCODE/Mon/ENCSR000EPK_rep2_1_se_bwa_biorep_filtered_peaks.bed')\n",
    "        DNase_data = readin_ATACseq(DNase_fn)\n",
    "        \n",
    "        filename = 'eQTL/FairFax/%s_cis_%i_fdr05_50kb_annotated.csv' % (celltype,chr)    \n",
    "        data = pd.read_csv(os.path.join(DATA_DIR, filename), sep='\\t')\n",
    "        result_df = eQTL_in_ATACseq_one_cell(data, DNase_data, SNP_ATAC_window, gene_ATAC_window)\n",
    "        result_df.to_csv(filename, sep='\\t', index=False)\n",
    "\n",
    "        filename = 'eQTL/FairFax/%s_cis_%i_fdr05_50kb_negative_annotated.csv' % (celltype,chr)\n",
    "        data = pd.read_csv(os.path.join(DATA_DIR, filename), sep='\\t')\n",
    "        result_df = eQTL_in_ATACseq_one_cell(data, DNase_data, SNP_ATAC_window, gene_ATAC_window)\n",
    "        result_df.to_csv(filename, sep='\\t', index=False)\n",
    "        \n",
    "    except:\n",
    "        print chr\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /Users/Yuan/Documents/BLab/Predict_target_genes/data/intermediate/Mon/motif/Mon.eSNP.1.negativeset.bed does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-983b7d0e038a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'eQTL/FairFax/%s_cis_%i_fdr05_50kb_negative_annotated.csv'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcelltype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_all_TF_motif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-11878b183c91>\u001b[0m in \u001b[0;36mmerge_all_TF_motif\u001b[0;34m(result_df, negative_set)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;31m# read in eQTLs with TF motif annotated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0meSNP_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'intermediate/%s/motif'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcelltype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m     \u001b[0megene_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'intermediate/%s/motif'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcelltype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File /Users/Yuan/Documents/BLab/Predict_target_genes/data/intermediate/Mon/motif/Mon.eSNP.1.negativeset.bed does not exist"
     ]
    }
   ],
   "source": [
    "chr=1\n",
    "\n",
    "filename = 'eQTL/FairFax/%s_cis_%i_fdr05_50kb_annotated.csv' % (celltype,chr)    \n",
    "data = pd.read_csv(os.path.join(DATA_DIR, filename), sep='\\t')\n",
    "result_df = merge_all_TF_motif(result_df, negative_set=False)\n",
    "result_df.to_csv(filename, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "filename = 'eQTL/FairFax/%s_cis_%i_fdr05_50kb_negative_annotated.csv' % (celltype,chr)\n",
    "data = pd.read_csv(os.path.join(DATA_DIR, filename), sep='\\t')\n",
    "result_df = merge_all_TF_motif(result_df, negative_set=True)\n",
    "result_df.to_csv(filename, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
